#!/usr/bin/env pinpoint

[fill]
[black]
[center]
[text-align=center]
[single-stop-light.jpg]

--

<span size="large" weight="heavy">Red, green, re-provision</span>
Test-Driven Operations

<span size="xx-small">R. Tyler Croy
tyler@linux.com</span>

# Thanks everybody for sticking around, this is the last block of talks for all
# of PuppetConf.


-- [lookout_frontdesk.jpg] [right]

I work here

-- [terminal_ruby.png]

As an app developer

# It really doesn't matter who am I. I might not be the most qualified to give
# this talk, but whatever, I'm here.


# What do Ops engineers and bananas have in common?  Neither of them are
# engineers.

--


<span size="large" weight="heavy">Let's talk testing</span>

# Before we dive into any of the operations-y bits, I'd like to first talk a
# little bit about testing in general.
#
# At the bottom of the totem pole, there's -->
--

<b>Manual Testing</b>

# Manual testing (explain)

--

<b>Unit Testing</b>

# Unit testing, what it typically means

--

<b>Integration Testing</b>

# Integration testing and how it pertains to the reactions between various
# components in a system

--

<b>Acceptance Testing</b>

# Acceptance testing, as in the over-arching, high-level test that effectively
# can verify "this is done" versus "not done"

--

# These are the various "buckets" to which "testing" applies. Let's now cover
# the basics of -->

--

<b>TDD</b>

# For the purposes of this talk, I will be referring to TDD as in "test-first
# development" that is to say you write a failing unit test that exhibits the
# functionality you wish to implement, then you implement it, turning the test
# green.
#
# This is where the notion of "red, green" comes from.
#
# What a number of people consider to have supercede, or further refined TDD,
# is -->

--

<b>BDD</b>

# BDD, as in Behavior Driven Development. BDD introduces the concept of
# "outside-in" focused development
#
# Is closely related, if not identical to -->

--

<b>ATDD</b>

--

neat

# So that's all neat I suppose, it's become fairly commonplace in most software
# shops, there are still stragglers who insist on doing all different kinds of
# manual testing and poorly specified software development.
#
# We'll forget about them for now, since they're wasting time and money
# building crappy products.
#
# Let's focus now more on Operations

--

close your eyes and imagine..

# imagine, if you will, the following scenario:
#
# The developers you work are building a new web service, and you've been
# tasked to work with them to make sure it gets provisioned and deployed.
#
--

what do you do?

# What do you do? Where do you start? Perhaps you already have a big monolithic
# Puppet repository where all service and application host are provisioned
# from. Maybe you don't.
#
# Do you dig through the Puppet Forge to find modules that meet your needs? How
# do you know they don't suck, or even work at all?
#
# Perhaps you just start a new git repository, and use Vagrant to start
# cobbling together the manifests needed to run this new service. Is any of
# that re-usable? Is it maintainable?
#
# Maybe you go another direction and use the Puppet staging host your company
# has and start adding manifests under `/etc/puppet`?
#
#
# What is the most maintainable work-flow which won't
# saddle you with technical debt in the future?
#
# First things first, you should probably take a deep breath, because chances
# are the dev team told you when they wanted to ship the project, instead of at
# the beginning -->

--

(this is why daddy drinks)

# which is prone to happening. on behalf of my fellow frantic app developer, I
# apologize.

--

A better approach

# I'm going to try to avoid being too presciptive here, so bear with me.
#
# Let's talk about applying fairly common practices from the software
# engineering world to operations.
#
# For starters, we're going to be good citizens and write Puppet modules to
# solve our problems. Secondly, we're going to appraoch the problem from the
# outside, and move inward with Cucumber first, then RSpec.
#
# This approach helps us think about problems in terms of where the borders
# between components are, and how different resources interact.
#
# This workflow is definitely a move away from what I'd classify as "the
# traditional sysadmin workflow", but the resulting Puppet modules should be
# more re-usable, refactorable and easier to maintain in the long run.

--

<b>but why?</b>

# but why go through all that trouble?

--

<b>Infrastructure as code</b>

# If we say that infrastructure is code, then we should really treat it like
# code. Software engineering has decades of research and real-world practice
# that has proven certain workflows to be ideal for greating higher quality
# code.
#


-- [cost-of-testing.png] [fit]

# If we refer to this amazing, very scientific graph I just found on my desk
# right after I drew it. The cost of testing and finding regressions on your
# local machine is going to be very low, this is the core concept behind all
# test-driven development, rapid iteration and failing very fast.
#
# If bugs/issues are found on a staging host, that likely means that other code
# has been merged and then "throughput' on the Git branch that is deployed to
# the staging environment must be paused so a change can be reverted, or a
# hotfix deployed.
#
# If a regression makes it all the way to production, the sky is the limit for
# how costly fixing the issue might be. It could down the entire site, it
# could reqyure costly data clean-up operations.
#
# Even if we use test-driven practices -->


--

Production won't be bug-free

# Production won't be bug free, some issues will slip through, that's an
# unfortunate fact of life. The goal here is to catch as many regressions or
# problems where it's cheapest to deal with them, on my local machine
#
# Another benefit of test-driving operations is that -->
--

clearer definition of work

# we can help create clearer definitions of the work that needs to be done.
# This really applies to BDD or ATDD where we specify "what we want to see" up
# front, which means that once those tests are green, we're done with the work,
# and we can ship it!

--

You love testing

# So now I've convinced you that writing tests is a good idea, even if you're
# not convinced, just nod your head and play along.
#
# If we want to take this outside-in testing approach, what does that look like
# for Operations?
#
# Before we dive in, I'd like to introduce some of the tools we'll be using -->

--

<b>Cucumber</b>
<span size="xx-small">http://cukes.info</span>

# We'll use Cucumber for defining our acceptance critiera; Cucumber itself is a
# plain-text tool that can map user defined strings to code underneath that
# actually runs the test

--

<b>rspec-puppet</b>
<span size="xx-small">http://rspec-puppet.com</span>

# RSpec itself, is a testing tool that a large proportion of the Ruby community
# uses, so it's fortunate that rspec-puppet exists as well.
#
# Unfortunately it doesn't look like there's any talks on rspec-puppet
# specifically this year, but if you'd like to learn more about it head to
# rspec-puppet.com where there's some simple tutorials
#

--

<b>Stakeholders</b>

# Stakeholders, who is "on the outside" of the work we're doing
#
# Let's sketch out what Developers as stakeholders would look like, to do this,
# we'll use Cucumber to enumerate this right off the bat

-- [font=monospace 50px] [text-align=left] [left]

Feature: Serve the PuppetConf streaming web service
  In order to serve up the PuppetConf
  video stream to millions of fans

  As a developer

  Web hosts should be configured to run the app


# This is just meta-data at the top of a `.feature` file for Cucumber, it
# serves no other purpose other than to help inform the reader of the
# context/goals of the feature
#
# In order to serve up the PuppetConf video stream to millions of fans
# As a developer
# Web hosts should be configured to run the app
#
# This feels a little janky. With my developer hat on, I really don't care all
# that mugh about how the application is configured, provisioned, or even run,
# so long as it just runs!
#
# What about Operatiosn as its own stakeholder?

-- [font=monospace 50px] [text-align=left] [left]

Feature: Serve the PuppetConf streaming web service
  In order to serve up the PuppetConf
  video stream to millions of fans

  As an Operations Engineer

  Web hosts should be configured to run the app

# I'll add in "As an Operations Engineer" and this reads a little bit better,
# although this is really just semantics at this point, what this tells me is
# that the contents of this .feature file are *for* Operations.
#
# Think of it more as executable documentation, with some goals in place. I
# think this is enough to really determine, at least at this step of the way,
# who the stakeholders for operational work are.
#
# I'm going to go ahead and create our a few scenarios for our streaming web
# service

-- [font=monospace 50px] [text-align=left] [left]

Scenario: Lock down SSH for all servers
  Given an empty host
  When I provision the host
  Then port 22 should be reachable
  And SSH should not permit password-less logins

-- [font=monospace 50px] [text-align=left] [left]

Scenario: Add a new stream server to the pool
  Given an new stream server
  When I provision the host
  Then the host should be added to the Nagios HTTP group
  And a new backend should be added to HAProxy

-- [font=monospace 50px] [text-align=left] [left]

Scenario: Set up a basic stream server
  Given an empty host
  And the host is classified as a www node
  When I provision the host
  Then it should be running a web server
  And it should be responding to web requests

--

<b>In Practice</b>

# This is all well and good, plain english non-sense that doesn't actually test
# anything, I'm going to take this last scenario and dig into it.

-- [font=monospace 50px] [text-align=left] [left]

Given an empty host

# This isn't terribly interesting, we're just stating that for the acceptance
# test we want to always start with a fresh host. It's more informative than
# anything here, so let's move on.

-- [font=monospace 50px] [text-align=left] [left]

And the host is classified as a www node

# While we are really talking about testing Puppet modules underneath the hood,
# notice that there's no mention of this in the step. We are hand-waving a
# concept into our Operations organization that means "a www node"
#
# This could mean we add a "www" module into our tree, but let's create a node
# definition -->

-- [font=monospace 50px] [text-align=left] [left]

node /^www\\d+\\.puppetlabs\\.com/ {
  include ssh
  include apache
  include stream-app
}

# So this is what we mean when we say "the host is classified as a www node".
# This does give us a couple modules to work with so let's -->

--

Drill inward

# Drill inward and start test-driving out the individual modules, for the
# interest of time, I'm going to focus on the "apache" module. We're not going
# to cheat and just grab the apache module from the forge for this exercise,
# but if I were doing this "for reals" then I would just grab that :)
#
#
# We'll start scaffolding out things -->

-- [font=monospace 50px] [text-align=left] [left]

<b>spec/classes/apache_spec.rb</b>
\--
describe 'apache' do

end

# In spec/classes/apache_spec.rb

-- [font=monospace 50px] [text-align=left] [left]

<b>modules/apache/manifests/init.pp</b>
\--
class apache {
}


-- [font=monospace 50px] [text-align=left] [left]

describe 'apache' do
  it { should contain_package('apache2') }
end

-- [font=monospace 50px] [text-align=left] [left]

class apache {
  package {
    'apache2' :
      ensure => installed;
  }
}

# Now we've impleented our first thing, and our test passes! Let's pretend that
# the stupid Ubuntu apache package doesn't start apache by default and run our
# Cucumber again. The test will still fail, unfortuantely, so let's add a
# service

-- [font=monospace 50px] [text-align=left] [left]

describe 'apache' do
  it { should contain_package('apache2') }
  it {
    should contain_service('apache2').with(
      'ensure' => 'running'
    )
  }
end

#

-- [font=monospace 50px] [text-align=left] [left]

class apache {
  package {
    'apache2' :
      ensure => installed;
  }
  service {
    'apache2' :
      ensure => running;
  }
}

# With this we can run Cucumber, maybe it passes, maybe it doesn't! We've
# left out a requires statement here, so the service resource isn't linked to
# the package.
#
# Let's fix that


-- [font=monospace 50px] [text-align=left] [left]

describe 'apache' do
  it { should contain_package('apache2') }
  it {
    should contain_service('apache2').with(
      'ensure'  => 'running',
      'require' => 'Package[apache2]'
    )
  }
end

-- [font=monospace 50px] [text-align=left] [left]

class apache {
  package {
    'apache2' :
      ensure => installed;
  }
  service {
    'apache2' :
      ensure  => running,
      require => Package[apache2];
  }
}

# Now things should pass in RSpec, and they should pass in Cucumber
--

neat!

--

<b>Monitoring in TDD-Ops?</b>

# I'm not really sure where monitoring fits into the picture, for me monitoring
# is something altogether separate from testing, mostly because I can't
# envision a monitoring-driven workflow
#
# Acceptance tests might turn into monitoring, or a subset of monitoring, that
# part I'm not sure of

--

<b>Other Tools</b>

-

puppetlabs_spec_helper

--

Cuken

--

cucumber-nagios

--

Vagrant

--

Blimpy

--

<b>Questions?</b>


--

<b>Thanks</b>

--

<b>Bonus Material!</b>

--
